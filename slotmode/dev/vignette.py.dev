# Piecewise Polinomial with boundary conditions
import warnings
import functools
# from textwrap import dedent
from collections import namedtuple

# import itertools as itt
import lmfit as lm
import numpy as np
from scipy.linalg import toeplitz, circulant
from scipy.special import factorial, binom
from scipy.interpolate import PPoly
import matplotlib.pyplot as plt

from recipes.iter import pairwise, roundrobin
from recipes.set import OrderedSet
from recipes.string import minfloatfmt, switchlogfmt
from obstools.psf.model import Model


def plist(params):  # can import from lm_compat
    """convert from lm.Parameters to ordered list of float values"""
    if isinstance(params, lm.Parameters):
        params = list(params.valuesdict().values())
    return np.asarray(params)

def convert_params(func):
    """decorator to convert lm.Parameters to a list on the fly"""

    @functools.wraps(func)
    def wrapper(*args, **kws):
        obj, p, *rest = args
        return func(obj, plist(p), *rest, **kws)

    return wrapper



def falling_factorial(n, k):
    n = np.asarray(n)
    k = np.asarray(k)
    with warnings.catch_warnings():
        warnings.filterwarnings('ignore', category=RuntimeWarning)
        return np.where(n < k, np.zeros_like(n * k), factorial(n) / factorial(n - k))


def transform_poly(coeff, scale, offset, increasing=False):
    """
    Transform polynomial coefficients in response to a linear transformation
    in domain (independent variable):  x = au + b

    Note: This transformation is non-linear in model space.

    Parameters
    ----------
    coeff
    offset
    increasing

    Examples
    --------
    >>> coeff = np.arange(5)
    >>> x = np.array([0, 1, 2])
    >>> scale, offset = 5, 3
    >>> a = np.polyval(coeff, x)
    >>> b = np.polyval(transform_poly(coeff, scale, offset), (x-offset) / scale)
    >>> np.allclose(a, b)
    Out[10]: True

    Returns
    -------

    """
    step = [-1, 1][increasing]
    rng = np.arange(len(coeff))
    n = rng[::step, None]
    opwrs = np.triu(circulant(rng).T) # powers of the offset term
    apwrs = np.tril(rng)[::-1, ::-1]  # powers of the scaling term
    b = binom(n.T, n).T # binomial coefficients for the sequence of powers
    B = b * np.power(scale, apwrs) * np.power(offset, opwrs)
    return np.sum(B * np.array(coeff)[None].T, 0)  # new coefficients for u



def get_param_coeff(x, o, nbc, increasing=True):
    """
    Get coefficients of linear system of parameters of the piecewise polynomial given the boundary
    conditions at the breakpoint *x*.

    Parameters
    ----------
    x : float
        break point
    o :- int
        order of the polynomial
    nbc : int
        number of derivatives to set equal at boundary
    increasing : bool
        whether the coefficient matrix should be increasing in powers of x

    Examples
    --------
    With o = 3, return lhs coefficients of the system of linear equations:
        p1(x)   = p2(0)
        p1'(x)  = p2'(0)
        p1''(x) = p2''(0)
    as an array
        [[ 1   1 x  1 x^2  1 x^3 ]                [[ 1 x^3  1 x^2  1 x  1 ]
         [ 0   1    2 x    3 x^2 ]      or         [ 3 x^2  2 x    1    0 ]
         [ 0   0    2      6 x   ]]                [ 6 x    2      0    0 ]]
        if increasing is True                     if increasing is False
    Returns
    -------
    array

    """

    P = np.zeros((nbc, o))
    pwrx = np.vander([x, ], N=o, increasing=True)  # increasing always True, otherwise can't use toeplitz
    P[:o] = toeplitz(pwrx)[:nbc]
    f = falling_factorial(np.arange(o),
                          np.arange(nbc)[None].T)
    step = [-1, 1][increasing]
    return (f * P)[:, ::step]


def make_pnames(orders, alpha='a', increasing=False, subscript=True, latex=True):
    """
    Get a list of parameter names eg: [a0, a1, a2, a3, b0, b1, c0, d0, ...]
    Parameter names will be enumerated as 'a0-an' for the first polynomial,
    'b0-bm' for the second etc.

    Parameters
    ----------
    orders : array-like
        orders of polynomials

    Returns
    -------
    list of strings

    """
    ch = ord(alpha)
    names = []
    if subscript:
        if latex:
            fmt = '$%s_{{{}}}$'
        else:
            fmt = '%s_{}'
    else:
        fmt = '%s{}'


    step = [-1, 1][increasing]
    for i, o in enumerate(orders):
        char = chr(ch + i)
        base = fmt % char
        names.extend(map(base.format, range(o + 1)[::step]))
    return np.array(names)


def get_poly_repr(p, variable='x', increasing=False, precision=2, logswitch=None,
                  minimalist=True, multsym=r'\times'):
    """
    Produce a latex string representing a polynomial

    Parameters
    ----------
    coeff : array-like
        coefficients
    variable: str
        variable name
    increasing : bool
        order of the powers
    precision : int
        numerical precision for coefficients
    minimalist : bool
        whether to represent floats as shortest possible string for given precision
    logswitch : float
        order of magnitude at which to switch to exponential formatting for coefficients

    Returns
    -------
    str

    Examples
    --------
    get_poly_repr([-2, -1, 2, 2.104302], minimalist=False)
    Out[215]: '- 2.00x^{3} - 1.00x^{2} + 2.00x + 2.10'
    """

    # todo: handle 2D poly

    # number of terms
    n = len(p)

    # get sequence of exponents
    step = [-1, 1][increasing]
    pwr = np.arange(n)[::step]
    ignore_variable = (pwr == 0)  # since x**0 == 1
    ignore_exp = (pwr == 1)  # exponent of 1 redundant

    # convert powers to latex exponents
    pwr = np.char.mod('^{%i}', pwr)
    pwr[ignore_exp | ignore_variable] = ''

    # raise variable to powers
    variables = np.array([variable] * n)
    variables[ignore_variable] = ''
    vpwr = np.char.add(variables, pwr)

    return lincombfmt(p, vpwr, precision, minimalist, logswitch, multsym)


def lincombfmt(coeff, variables, precision=2, minimalist=True, logswitch=None, multsym=r'\times'):

    # number of terms
    n = len(coeff)
    if isinstance(variables, str):
        variables = [variables] * n

    # handle coefficient formatting
    coeff = np.asarray(coeff)
    if np.issubdtype(coeff.dtype, np.number):
        # if we have numeric coefficients
        ignore_terms = (coeff == 0)
        # get signs of coefficients
        signs = np.take(['', '+', '-'], np.sign(coeff).astype(int))
        signs = np.char.add(signs, ' ')  # add space for aesthetic
        # convert to nice str format
        cfmt = np.vectorize(switchlogfmt, excluded=[1, 2, 3, 4, 5])
        coeff = cfmt(np.abs(coeff), precision, logswitch, minimalist, multsym, False)
        coeff[(coeff == '1')] = '' # don't need to display 1s (implicit)
    else:
        ignore_terms = np.char.str_len(coeff) == 0
        signs = np.array(['+ '] * n)

    coeff = np.char.add(signs, coeff)
    terms = np.char.add(coeff, variables)
    equation = ' '.join(terms[~ignore_terms])
    return equation.strip('+ ')


def mad(data, data_median=None, axis=None):
    """
    Median absolute deviation

    Parameters
    ----------
    data
    data_median

    Returns
    -------

    """
    if data_median is None:
        data_median = np.ma.median(data, axis, keepdims=True)
    return np.ma.median(np.abs(data - data_median), axis)

def get_cross_section_data(image, i, masked_ignore_thresh=0.25):
    # extract the data
    other_axis = int(not bool(i))
    m = np.ma.median(image, other_axis)

    # make mask
    mask = image.mask.mean(other_axis) > masked_ignore_thresh
    cross_masked = np.ma.masked_array(m, mask=mask)
    # scale data - polynomial fitting better behaved
    scale = np.ma.median(image)
    data = cross_masked / scale

    #grid = np.linspace(0, 1, image.shape[i])
    # print('!!', i, image.shape[i])
    grid = np.mgrid[0:image.shape[i]]
    uncertainty = mad(image, axis=other_axis) / scale
    # uncertainty = np.ones_like(data)

    return grid, data, uncertainty, scale


class SmoothPiecewisePolynomial():

    def __init__(self, orders, breakpoints, nbc=2, coeffNameBase='a'):
        """
        Create a smooth piecewise polynomial from orders and break points

        # TODO: equations: see scipy.interpolate.PPoly
        # constraints


        Parameters
        ----------
        orders : array-like
            Polynomial orders
        breakpoints : array-like
            Location of break points (boundaries between different polynomials)
        nbc : int
            number of boundary conditions at each of the breakpoints.
            nbc = 1 will produce a continuous polynomial
            nbc =2 will produce a continuous, smooth polynomial

        Attributes
        ----------
        todo

        Methods
        -------
        todo

        See also
        --------
        scipy.interpolate.PPoly

        Notes
        -----
        Important: Even though the break points passed to this class are
        given wrt the same coordinate system (that of the first polynomial),
        each polynomial segment is internally calculated in it's own domain
        (x-coordinates) ranging from zero, to the value next break point.
        This is is the same as `scipy.interpolate.PPoly`

        """
        # nbc -
        # {1, 2} ==> 1st, 2nd derivative equal at break points for adjoining functions

        # use boundary conditions to constrain parameter space
        bp = breakpoints[1:]  # no constraint provided by 1st breakpoint
        if isinstance(orders, float):
            orders = int(orders)
        if isinstance(orders, int):
            orders = [orders] * len(bp)
        if len(orders) != len(bp):
            raise ValueError('Order / breakpoint size mismatch: %i, %i'
                             %(len(orders), len(breakpoints)))

        self.coeffNameBase = coeffNameBase
        self.orders = np.array(orders)
        self.breakpoints = bp = np.asarray(breakpoints)
        self._scale = bp.max()
        self.npoly = npoly = len(orders)
        ncoeff = self.ncoeff = self.orders + 1
        self.npar = ncoeff.sum()  # number of parameters (unconstrained)
        self.nbc = int(nbc)

        # represent each polynomial internally on a domain for robustness (-1, 1
        self.intervals = intervals = np.array(list(pairwise(bp)))
        # self.scales = scales = 2 / np.diff(self.breakpoints)[None].T
        # self.offsets = -intervals[:, None, 0] * scales - 1
        # map form breakpoint intervals to (-1, 1) with (x - offset) / scale

        self.nconstraints = nbc * (npoly - 1)
        self.nfree = self.npar - self.nconstraints
        # handle constraints
        # self.A = self.get_constraints()
        self.constraints, self.coeffmap, self.dont_fit = self.get_constraint_matrix()
        self.to_fit = list(set(range(self.npar)) - set(self.dont_fit))
        # self.to_fit = list(to_fit)


    def get_constraint_matrix(self):
        # NOTE: the block below can often not eliminate higher powers of x since
        # it leads to a singular linear system (this is largely due to the
        #  independent domains of each polynomial (starting from 0) and therefore
        #  the large number of 0s in the constraining system. one way past this
        # would be to formulate to transform to a different domain (1,2) maybe,
        # solve the system, and then transform back via binomial equation...
        # This will mean changing coordinates after applying the constraints in the
        # call method
        # coefficients are given in decreasing powers of x by default

        # Construct the linear system that imposes constraints in N x M
        # scale = self.breakpoints.max()
        bp = self.breakpoints / self._scale
        nbc = self.nbc
        ncoeff = self.ncoeff
        cso = np.cumsum(np.r_[0, ncoeff])  # cumulative sum of polynomial orders starting at 0 (used for indexing below)
        N = self.nconstraints
        M = self.npar
        A = np.zeros((N, M))
        increasing = False
        for n, x in enumerate(np.diff(bp[:-1])):
            i = n * nbc
            j = cso[n]
            o = ncoeff[n]
            lhs = A[i:i + nbc, j:j + o] = get_param_coeff(x, o, nbc, increasing)

            #x =
            j = cso[n + 1]
            o = ncoeff[n + 1]
            rhs = A[i:i + nbc, j:j + o] = -get_param_coeff(0, o, nbc, increasing)

        # Get indices of parameters to be fit by reducing the linear system
        q, r = np.linalg.qr(A) # A = q.dot(r)
        self.A = A

        # prefer to fit parameters corresponding to smaller power in x (numerically more stable?)
        prefer = roundrobin(*(range(*nrs)[::-1] for nrs in pairwise(cso)))
        eliminate = OrderedSet(list(prefer)[::-1])  # preferred parameters to eliminate
        dont_fit = []
        while len(dont_fit) < self.nconstraints:
            # make sure we end up with a parameter selection that gives non-singular matrix
            unavailable, = np.where(np.isclose(r[len(dont_fit)], 0))
            choices = eliminate - set(unavailable)
            choice = next(iter(choices))
            dont_fit.append(choice)
            eliminate -= {choice}

        # dont_fit = [0, 1]

        # reduce the system so that we can solve the *N* parameters in *dont_fit*
        S = np.linalg.inv(A[:, dont_fit])
        constraints = S.dot(A)  # columns in *dont_fit* will now have one 1, and all zeros further
        # remove them so we can obtain their values by dotting the rows of this matrix
        constraints = -np.delete(constraints, dont_fit, axis=1)
        # now we can do  self.constraints.dot(p) to solve the *N* parameters
        # constrained by the linear system in *A*

        # map coefficients to block
        mxo = self.ncoeff.max()
        coeff = np.ones((self.npoly, mxo))  # easier to work with block data
        for i, o in enumerate(self.orders):
            e = max(mxo - o - 1, 0)
            coeff[i, :e] = 0
        coeffmap = np.array(np.where(coeff))
        # this is an array with equation number in first row and corresponding
        # parameter number in second row. The columns therefor map to a index
        # in the full coefficient block

        return constraints, coeffmap, dont_fit

    def __call__(self, p, grid):

        if len(p) != self.nfree:
            raise ValueError('%s takes %i free parameters, %i given.'
                             % self, self.nfree, len(p))

        coeff = self.get_block_coeff(p, False)
        pp = PPoly(coeff.T, self.breakpoints / self._scale)
        return pp(grid)

    def __str__(self):
        p = self.get_pnames(free=True, latex=False)
        return self.get_repr(p)


    def get_pnames(self, alpha=None, free=False, increasing=False, subscript=True,
                   latex=True):
        """
        Get a list of parameter names eg: [a0, a1, a2, a3, b0, b1, c0, d0, ...]
        Parameter names will start from 'a0' for the first polynomial, 'b0' for
        the second etc.

        Parameters
        ----------
        alpha : str
            letter to start with for names
        free : bool
            whether to return only the free parameter names, or the full set

        Returns
        -------
        list of strings
        """
        alpha = alpha or self.coeffNameBase
        names = make_pnames(self.orders, alpha, increasing, subscript, latex)
        if free:
            return names[self.to_fit]
        return names


    def get_repr(self, coeff, name='f', variable='x', increasing=False, onedomain=True,
                 precision=2, minimalist=True, logswitch=None, multsym='\cdot'):
        """
        Produce a latex string representing a polynomial

        Parameters
        ----------
        coeff : array-like
            coefficients
        variable: str
            variable name
        increasing : bool
            order of the powers
        precision : int
            numerical precision for coefficients
        minimalist : bool
            whether to represent floats as shortest possible string for given precision

        Returns
        -------
        str

        Returns
        -------
        str or IPython display object
        """
        from recipes.iter import pairwise
        from recipes.interactive import is_interactive

        fmtargs = precision, logswitch, minimalist, multsym

        coeff = np.asarray(coeff)
        if np.issubdtype(coeff.dtype, np.number):
            # numerical coefficients
            block = self.get_block_coeff(coeff, onedomain)
        else:
            # str coefficients
            # get expression for derived coefficients
            dcoeff = []
            for i, cr in enumerate(self.constraints):
                q = lincombfmt(cr, coeff)
                if np.sum(cr != 0) > 1:
                    q = '(%s)' % q
                dcoeff.append(q)

            dtype = 'U%i' % np.char.str_len(dcoeff).max()
            block = np.empty((self.npoly, self.ncoeff.max()), dtype)
            iy, ix = self.coeffmap[:, self.dont_fit]
            block[iy, ix] = dcoeff
            #
            iy, ix = self.coeffmap[:, self.to_fit]
            block[iy, ix] = coeff

        # create piecewise latex equation
        intervals = pairwise(self.breakpoints)
        rep = r'%s\left(%s\right) = \begin{cases}' % (name, variable)
        for i, (p, intr) in enumerate(zip(block, intervals)):
            if not onedomain:
                variable = '%s_{%i}' % (variable, i)
                intr = (0, np.diff(intr)[0])

            eq = get_poly_repr(p, variable, increasing, *fmtargs)
            i0, i1 = (switchlogfmt(_, *fmtargs, latex=False) for _ in intr)
            rep += r'%s &\mbox{if } %s \leq %s < %s \\' % (eq, i0, variable, i1)
        rep += '\end{cases}'

        if is_interactive():
            from IPython.display import display, Math#, Latex
            display(Math(rep))
            return ''
        return rep

    # def free(self):
    #     np.take(my.get_pnames(), [my.to_fit])

    def get_constrained(self, p):
        """
        Derive the parameters fixed by the boundary constraints from the free
        parameters.
        """
        return self.constraints.dot(p)

    def get_block_coeff(self, p, onedomain=False):
        """
        Get the full set of coefficients for all the polynomials as an MxN
        array (where M is the number of polynomials (pieces) and N is the
        degree of the highest order polynomial.  Those coefficients which can
        be algebraically determined by the constraints are filled. This set of
        coefficients returned by this method can be passed to
        scipy.interpolation.PPoly to construct a smooth piecewise polynomial
        (see __call__ method).

        Parameters
        ----------
        p - parameter values

        Returns
        -------
        coeff : array
        """
        c = np.empty(self.npar)
        c[self.to_fit] = p
        constrained = self.constraints.dot(p)
        c[self.dont_fit] = constrained

        coeff = np.zeros((self.npoly, self.ncoeff.max()))
        coeff[tuple(self.coeffmap[:, self.to_fit])] = p
        coeff[tuple(self.coeffmap[:, self.dont_fit])] = constrained

        # if not onedomain:
        #     s = self._scale
        #     for i, c in enumerate(coeff):
        #         o = self.breakpoints[i] / s
        #         coeff[i] = transform_poly(c, 1/s, o)

        # if not onedomain:
        #     s = self._scale
        #     for i, c in enumerate(coeff):
        #         o = 0 #self.breakpoints[i] / s
        #         coeff[i] = transform_poly(c, 1/s, o)

        return coeff


    def check(self, p=None):
        # check that boundary conditions are satisfied
        if p is None:
            p = np.random.randn(self.nfree)
        coeff = self.get_block_coeff(p)
        lhs = np.polyval(coeff.T, 0)[1:]
        rhs = list(map(np.polyval, coeff, np.diff(self.breakpoints[:-1])))
        assert np.allclose(lhs, rhs)




class SmoothPPolyLM(SmoothPiecewisePolynomial, Model):

    # def __init__(self, orders, breakpoints, nbc=2, coeffNameBase='a'):
    #     # scale breakpoints to unit interval for numerical stability
    #     # self._gridscale = np.max(breakpoints)
    #     # breakpoints = breakpoints / self._gridscale
    #     SmoothPiecewisePolynomial.__init__(self, orders, breakpoints, nbc, coeffNameBase)

        #     @property
        #     def breakpoints(self):
        #         return self._breakpoints * self._gridscale

    # @convert_params
    # def __call__(self, p, grid):
    #     # scale grid to match rescaled breakpoints
    #
    #     # print(self)
    #     # print(grid[[0, -1]], self._gridscale)
    #     # grid = grid / self._gridscale
    #     # print(grid[[0, -1]])
    #     # print('!!')
    #     return SmoothPiecewisePolynomial.__call__(self, p, grid)

    def make_params(self, p0=None, namebase=None):
        # create parameters
        if p0 is None:
            p0 = np.ones(self.nfree)

        pars = lm.Parameters()
        # lm doesn't like non alpha numeric characters as parameter names
        pnames = self.get_pnames(namebase, free=True, latex=False)
        for pn, p in zip(pnames, p0):
            pars.add(pn, p)
        return pars

    __call__ = convert_params(SmoothPiecewisePolynomial.__call__)
    get_repr = convert_params(SmoothPiecewisePolynomial.get_repr)
    get_block_coeff = convert_params(SmoothPiecewisePolynomial.get_block_coeff)



class SmoothPPolyLMCross(SmoothPPolyLM):
    def __init__(self, orders, breaks, nbc=2, axis=0, coeffNameBase='a'):
        SmoothPPolyLM.__init__(self, orders, breaks, nbc, coeffNameBase)
        self._axis = int(axis)

    def get_cross_section_data(self, image, masked_ignore_thresh=0.25):
        # extract the data
        other_axis = int(not bool(self._axis))
        m = np.ma.median(image, other_axis)

        # make mask
        mask = image.mask.mean(other_axis) > masked_ignore_thresh
        cross_masked = np.ma.masked_array(m, mask=mask)
        # scale data - polynomial fitting better behaved
        scale = np.ma.median(image)
        data = cross_masked / scale

        # grid = np.linspace(0, 1, image.shape[i])
        # print('!!', i, image.shape[i])
        grid = np.mgrid[0:image.shape[self._axis]] / self._scale
        uncertainty = mad(image, axis=other_axis) / scale
        # uncertainty = np.ones_like(data)

        return grid, data, uncertainty, scale

    def plot_fit_results(self, image, params, modRes=500):
        # plot fit result
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8),
                                       sharex=True,
                                       gridspec_kw=dict(hspace=0, height_ratios=(3, 1)))

        # get data
        i = self._axis
        axs = 'yx'[i]
        grid, data, uncertainty, scale = g, d, e, s =\
            self.get_cross_section_data(image, i)

        # plot fitted data
        ebc = ax1.errorbar(g, d, e, fmt='mo', zorder=10,
                           label='Median $\pm$ (MAD)')

        # plot rows / column data
        pixels = image / scale
        if i == 1:
            pixels = pixels.T

        lines = ax1.plot(g, pixels, 'g', alpha=0.35, label='Data')

        # breakpoints
        # print(axs, 'breaks', db.model[axs].breakpoints)
        breakpoints = self.breakpoints# * g.max()
        lines_bp = ax1.vlines(breakpoints, 0, 1,
                              linestyle=':', color='0.2',
                              transform=ax1.get_xaxis_transform(),
                              label='Break points')

        # model
        gm = np.linspace(0, g.max(), modRes)  # bg.shape[not bool(i)]
        dfit = self(params, gm)
        lines_mdl, = ax1.plot(gm, dfit, 'r-', label='model')

        # plot model residuals
        res = self.residuals(params, data, grid)
        ax2.errorbar(g, res, e, fmt='mo')
        # percentile limits on errorbars (more informative display for large errorbars)
        lims = np.percentile(res - e, 25), np.percentile(res + e, 75)
        ax2.set_ylim(*lims)

        ax1.set_title(('%s cross section fit' % axs).title())
        ax1.set_ylabel('Normalized Counts')
        legArt = [ebc, lines[0], lines_mdl, lines_bp]
        legLbl = [_.get_label() for _ in legArt]
        ax1.legend(legArt, legLbl)
        ax1.grid()

        ax2.set_ylabel('Residuals')
        ax2.grid()

        fig.tight_layout()
        return fig


class Vignette2DCross(Model):
    """
    Fit the background median cross sections (after stars have been masked)
    This seems to behave better than fitting the full 2D model with LM optimization algorithm
    """

    def __init__(self, xorders, xbreaks, yorders, ybreaks):
        # initialize models
        mdlx = SmoothPPolyLMCross(xorders, xbreaks, 2, 1, 'a')
        mdly = SmoothPPolyLMCross(yorders, ybreaks, 2, 0, 'r')
        self.models = namedtuple('Models', ['y','x'])(mdly, mdlx)

    def __call__(self, p, grid):

        py, px = np.split(plist(p), [self.models.y.nfree])

        zy = self.models.y(py, grid[0])
        zx = self.models.x(px, grid[1])

        return np.outer(zy, zx)

    def residuals(self, p, data, grid):
        '''Difference between data and model'''
        # HACK since we are computing via outer product can't directly apply mask
        res = data - self(p, grid)
        if np.ma.is_masked(res):
            return res[~res.mask]
        return res

    @property
    def nfree(self):
        return self.models.x.nfree + self.models.y.nfree

    def fit_cross_y(self, image):
        return self._fit_cross(image, 0)

    def fit_cross_x(self, image):
        return self._fit_cross(image, 1)

    def _fit_cross(self, image, i, masked_ignore_thresh=0.25, report=True):

        mdl = self.models[i]
        grid, data, uncertainty, scale = \
            mdl.get_cross_section_data(image, masked_ignore_thresh)
        # uncertainty[data.mask] = np.inf

        # print(grid[[0, -1]])
        # print('----')

        mdl = self.models[i]
        pars = mdl.make_params()

        # NOTE: convergence behaviour worse if masked arrays used and corresponding uncertainty set to inf.
        result = lm.minimize(mdl.wrs, pars,
                             args=(data[~data.mask], grid[~data.mask], None))

        # print report
        if report:
            print(' %s \n---\n' % 'YX'[i])
            print(lm.fit_report(result))

        return result

    def fit_cross(self, image, masked_ignore_thresh=0.25, report=True):

        results = []
        for i in (0, 1):
            r = self._fit_cross(image, i, masked_ignore_thresh, report)
            results.append(r)

        return results

    # def fit(self, image):


        #     def fit(self, p0, grid, data, std=None):

        #         if np.ma.is_masked(data):
        # #             if std is not None:
        # #                 std = std[~data.mask]
        #             data = data[~data.mask]

        #         return lm.minimize(self.wrs, p0, args=(data, grid, std))

# class Vignette(SmoothPiecewisePolynomial, Model):
#     pass


if __name__ == '__main__':
    from matplotlib import pyplot as plt

    orders_x, bpx = (1, 5), (0, 161.5, image.shape[1])
    orders_y, bpy = (3, 1, 5), (0, 3.5, 17, image.shape[0])
    v2 = Vignette2DCross(orders_x, bpx, orders_y, bpy)
    self = mdl = v2.models.x

    fig, (ax1, ax2, ax3) = plt.subplots(3, 1)

    p = np.random.randn(mdl.nfree)  # np.ones(mdl.nfree)#
    coeff = self.get_block_coeff(p, True)
    xres = 500

    scale = self.breakpoints.max()
    bp = self.breakpoints / scale
    for i, (i0, i1) in enumerate(pairwise(bp)):
        c = coeff[i]
        x = np.linspace(i0, i1, xres)
        y = np.polyval(c, x)

        ax1.plot(x, y)

        o = self.breakpoints[i] / scale
        s = 1 / scale
        c2 = transform_poly(c, s, o)
        x2 = (x - o) / s

        # print(c)
        # print(x[[0, -1]])
        # print(x2[[0, -1]])

        y2 = np.polyval(c2, x2)
        ax2.plot(x2, y2)

    X = np.linspace(self.breakpoints.min(), self.breakpoints.max(), xres)
    # coeff = self.get_block_coeff(p)
    # for i, c in enumerate(coeff):
    #    coeff[i] = transform_poly(c, 1, self.breakpoints[i])

    # pp = PPoly(coeff.T, self.breakpoints)
    # X = np.linspace(0, 1, xres)
    ax3.plot(X, self(p, X))